{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufofon2/korea/blob/master/06_rag_answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5cngZTdQPf4"
      },
      "source": [
        "### 환경변수 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL1-sy4DQPf4"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
        "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJmei9jHQPf5"
      },
      "source": [
        "### Pinecone 벡터스토어를 이용한 유사도 검색\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uji5uO7rQPf5"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# Pinecone 객체를 초기화합니다.\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "# 인덱스 이름을 설정합니다.\n",
        "index_name = \"wiki\"\n",
        "\n",
        "# 인덱스를 초기화합니다.\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# 인덱스의 통계 정보를 출력합니다.\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FipgfHuxQPf5"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# OpenAIEmbeddings 객체를 초기화합니다.\n",
        "# 모델은 \"text-embedding-3-small\"을 사용하고, API 키는 OPENAI_API_KEY를 사용합니다.\n",
        "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVRyZo89QPf6"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# PineconeVectorStore 객체를 초기화합니다.\n",
        "# 인덱스는 이전에 정의된 index 객체를 사용하고, 임베딩은 embedding 객체를 사용합니다.\n",
        "# 텍스트 키는 \"full_text\"로 설정합니다.\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embedding, text_key=\"full_text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpV6TWySQPf6"
      },
      "outputs": [],
      "source": [
        "# 질문을 정의합니다.\n",
        "question = \"벨기에(Belgium)는 어디 있나요?\"\n",
        "\n",
        "# 질문에 대한 유사도 검색을 수행합니다.\n",
        "# query는 question을 사용해, wiki-ns1 네임스페이스의 상위 5개의 결과를 반환합니다.\n",
        "docs = vector_store.similarity_search(query=question, k=5, namespace=\"wiki-ns1\")\n",
        "print(docs)\n",
        "\n",
        "# 검색된 문서의 메타데이터를 출력합니다.\n",
        "for doc in docs:\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jMwEU5ZQPf6"
      },
      "source": [
        "### 프롬프트에서 RAG 결과 사용하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d77JbpRmQPf6"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# ChatOpenAI 객체를 초기화합니다.\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", api_key=OPENAI_API_KEY)\n",
        "\n",
        "# 여행할 국가를 설정합니다.\n",
        "country = \"벨기에(Belgium)\"\n",
        "\n",
        "# ChatPromptTemplate 객체를 초기화합니다.\n",
        "# 시스템 메시지와 사용자 메시지를 포함한 프롬프트 템플릿을 정의합니다.\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"당신은 베테랑 여행 가이드로, 고객 최적의 맞춤 여행 일정 수립을 도와줍니다.\"),\n",
        "    (\"human\", \"\"\"저는 {country} 여행을 계획하고 있습니다.\n",
        "                 {country}에서 무엇을 할 수 있을지 조언해 주세요.\n",
        "                 아래의 context에서만 정보를 사용하고 다른 정보는 사용하지 마세요.\n",
        "                 context:\n",
        "                 {context}\"\"\"),\n",
        "])\n",
        "\n",
        "# 유사도 검색을 위한 쿼리를 정의합니다.\n",
        "query = f\"{country}는 어디 있나요?\"\n",
        "\n",
        "# 벡터 스토어에서 유사도 검색을 수행하여 상위 5개의 결과를 반환합니다.\n",
        "results = vector_store.similarity_search(query=query, k=5, namespace=\"wiki-ns1\")\n",
        "\n",
        "# 검색 결과를 기반으로 context를 생성합니다.\n",
        "context = \"\"\n",
        "for result in results:\n",
        "    context += result.page_content\n",
        "\n",
        "# 프롬프트 템플릿을 사용하여 메시지를 포맷합니다.\n",
        "prompt = chat_template.format_messages(country=country, context=context)\n",
        "print(prompt)\n",
        "\n",
        "# LLM을 사용하여 프롬프트에 대한 응답을 생성합니다.\n",
        "response = llm.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pfoQZrQQPf6"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain_rag_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}